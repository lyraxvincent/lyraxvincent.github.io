<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Machine Learning on Vincent N.</title><link>https://lyraxvincent.github.io/categories/machine-learning/</link><description>Recent content in Machine Learning on Vincent N.</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Fri, 14 Jul 2023 20:58:49 +0530</lastBuildDate><atom:link href="https://lyraxvincent.github.io/categories/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Efficient Python and Machine Learning Environment Setup with Pyscaffold, Poetry, and Pyenv</title><link>https://lyraxvincent.github.io/post/efficient-python-and-machine-learning-environment-setup-with-pyscaffold/</link><pubDate>Fri, 14 Jul 2023 20:58:49 +0530</pubDate><guid>https://lyraxvincent.github.io/post/efficient-python-and-machine-learning-environment-setup-with-pyscaffold/</guid><description>Setting up development environment for python packages and machine learning projects
Setting up a python environment for machine learning can be tedious especially because we want to go right into getting our hands dirty with the data and ML algorithms, whether it&amp;rsquo;s just a project directory or you want to package your machine learning code. Python packaging has been made easier by a set of automation tools, in this article, I&amp;rsquo;ll be exploring what I&amp;rsquo;ve found to be a rewarding approach of how best to structure a development environment using these readily available tools.</description></item><item><title>Datastand, a Python Package for Data Explorers</title><link>https://lyraxvincent.github.io/post/datastand-a-python-package-for-data-explorers/</link><pubDate>Wed, 19 Jan 2022 15:44:46 +0300</pubDate><guid>https://lyraxvincent.github.io/post/datastand-a-python-package-for-data-explorers/</guid><description>Why datastand? Data + Understand
A python package to help Data Scientists, Machine Learning Engineers and Analysts better understand data. Gives quick insights about a given dataset:
general dataset statistics size and shape of dataset number of unique data types number of numerical and non- numerical columns small overview of dataset missing data statistics missing data heatmap and provides methodology to impute missing data Installation Run the following command on the terminal to install the package:</description></item><item><title>Monitoring machine learning model performance the right way to avoid overfitting the leaderboard in a competition</title><link>https://lyraxvincent.github.io/post/monitoring-machine-learning-model-performance-the-right-way-to-avoid-overfitting-the-leaderboard-in-a-competition/</link><pubDate>Thu, 13 Jan 2022 23:39:00 +0000</pubDate><guid>https://lyraxvincent.github.io/post/monitoring-machine-learning-model-performance-the-right-way-to-avoid-overfitting-the-leaderboard-in-a-competition/</guid><description>Photo by Charles Deluvio on Unsplash Introduction There are several explanations of what overfitting or underfitting is, whatever works for you, add the following idea to it:
An overfitting model/algorithm is too complex for the task or dataset at hand while An underfitting model is too simple for the task If overfitting has ever cost you downward jumps on a machine learning competition, you might agree with me that the experience was somewhat humiliating especially if you went from top 3 downwards, when you had better and stronger non-overfitting submissions that you didn&amp;rsquo;t select to be scored on.</description></item><item><title>Feature Engineering: deriving statistical features using pandas aggregate function</title><link>https://lyraxvincent.github.io/post/feature-engineering_-deriving-statistical-features-using-pandas-aggregate-function/</link><pubDate>Sun, 09 Jan 2022 20:58:49 +0530</pubDate><guid>https://lyraxvincent.github.io/post/feature-engineering_-deriving-statistical-features-using-pandas-aggregate-function/</guid><description>Many times when dealing with anonymized or machine-generated datasets, you find yourself out of ideas to come up with new features because it is unclear of what the dataset variables at hand represent. Take for example the following dataframe:
1 2 3 4 5 import pandas as pd df = pd.read_csv(&amp;#34;../datasets/Updated_Test.csv&amp;#34;) data = df[df.columns[2:13]].head(10) data absorbance0 absorbance1 absorbance2 absorbance3 absorbance4 absorbance5 absorbance6 absorbance7 absorbance8 absorbance9 absorbance10 0 0.517951 0.520508 0.</description></item></channel></rss>