<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Machine Learning on Vincent N.</title><link>https://lyraxvincent.github.io/categories/machine-learning/</link><description>Recent content in Machine Learning on Vincent N.</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Thu, 13 Jan 2022 23:39:00 +0000</lastBuildDate><atom:link href="https://lyraxvincent.github.io/categories/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Monitoring machine learning model performance the right way to avoid overfitting the leaderboard in a competition</title><link>https://lyraxvincent.github.io/post/monitoring-machine-learning-model-performance-the-right-way-to-avoid-overfitting-the-leaderboard-in-a-competition/</link><pubDate>Thu, 13 Jan 2022 23:39:00 +0000</pubDate><guid>https://lyraxvincent.github.io/post/monitoring-machine-learning-model-performance-the-right-way-to-avoid-overfitting-the-leaderboard-in-a-competition/</guid><description>Photo by Charles Deluvio on Unsplash Introduction There are several explanations of what overfitting or underfitting is, whatever works for you, add the following idea to it:
An overfitting model/algorithm is too complex for the task or dataset at hand while An underfitting model is too simple for the task If overfitting has ever cost you downward jumps on a machine learning competition, you might agree with me that the experience was somewhat humiliating especially if you went from top 3 downwards, when you had better and stronger non-overfitting submissions that you didn&amp;rsquo;t select to be scored on.</description></item><item><title>Feature Engineering: deriving statistical features using pandas aggregate function</title><link>https://lyraxvincent.github.io/post/feature-engineering-deriving-statistical-features-using-pandas-aggregate-function/</link><pubDate>Sun, 09 Jan 2022 20:58:49 +0530</pubDate><guid>https://lyraxvincent.github.io/post/feature-engineering-deriving-statistical-features-using-pandas-aggregate-function/</guid><description>Many times when dealing with anonymized or machine-generated datasets, you find yourself out of ideas to come up with new features because it is unclear of what the dataset variables at hand represent. Take for example the following dataframe:
1 2 3 4 5 import pandas as pd df = pd.read_csv(&amp;#34;../datasets/Updated_Test.csv&amp;#34;) data = df[df.columns[2:13]].head(10) data absorbance0 absorbance1 absorbance2 absorbance3 absorbance4 absorbance5 absorbance6 absorbance7 absorbance8 absorbance9 absorbance10 0 0.</description></item></channel></rss>